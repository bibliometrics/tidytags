---
title: "Using tidytags with a conference hashtag"
author: "K. Bret Staudt Willet & Joshua M. Rosenberg"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using tidytags with a conference hashtag}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
 library(tidytags)
```

This vignette introduces how to use many {tidytags} functions through the example of analyzing tweets associated with the 2019 annual convention of the [Association for Educational Communications & Technology](https://aect.org/) (AECT): `#aect19`, `#aect2019`, or `#aect19inspired`.

The information in this vignette is available scattered throughout the R documentation. This appendix brings it all together in one place.

## Considerations Related to Ethics, Data Privacy, and Human Subjects Research

Before working through this demonstration of the capabilities of {tidytags}, please take a few moments to reflect on ethical considerations related to social media research.


{tidytags} should be used in strict accordance with Twitter's [developer terms](https://developer.twitter.com/en/developer-terms/more-on-restricted-use-cases).

Although most Institutional Review Boards (IRBs) consider the Twitter data that {tidytags} analyzes to _not_ necessarily be human subjects research, there remain ethical considerations pertaining to the use of the {tidytags} package that should be discussed. 

Even if {tidytags} use is not for research purposes (or if an IRB determines that a study is not human subjects research), "the release of personally identifiable or sensitive data is potentially harmful," as noted in the [rOpenSci Packages guide](https://devguide.ropensci.org/policies.html#ethics-data-privacy-and-human-subjects-research). Therefore, although you _can_ collect Twitter data (and you _can_ use {tidytags} to analyze it),    we urge care and thoughtfulness regarding how you analyze the data and communicate the results. In short, please remember that most (if not all) of the you collect may be about people---and [those people may not like the idea of their data being analyzed or included in research](https://journals.sagepub.com/doi/full/10.1177/2056305118763366). 

We recommend [the Association of Internet Researchers' (AoIR) resources related to conducting analyses in ethical ways](https://aoir.org/ethics/) when working with data about people. AoIR's [ethical guidelines](https://aoir.org/reports/ethics3.pdf) may be especially helpful for navigating tensions related to collecting, analyzing, and sharing social media data.

## Twitter Archiving Google Sheets

A core functionality of {tidytags} is collecting tweets continuously with a [Twitter Archiving Google Sheet](https://tags.hawksey.info/) (TAGS).

For help setting up your own TAGS tracker, see the [Getting started with tidytags](https://bretsw.github.io/tidytags/articles/setup.html) vignette, **Pain Point #1**.

## read_tags()

To simply view a TAGS archive, you can use `read_tags()`. Here, we've openly shared a [TAGS tracker](https://docs.google.com/spreadsheets/d/18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8) that has been collecting tweets associated with the AECT 2019 since September 30, 2019. Notice that this TAGS tracker is collecting tweets containing three different hashtags: `#aect19`, `#aect2019`, or `#aect19inspired`. As of September 30, 2020, this tracker had collected **2,564 tweets**. This tracker is active through today.

{tidytags} allows you to work with tweets collected by a TAGS tracker in R. This is done with the [{googlesheets4} package](https://CRAN.R-project.org/package=googlesheets4). One requirement for using {googlesheets4} is that your TAGS tracker has been "published to the web." To do this, with the TAGS page open in a web browser, go to `File >> Publish to the web`. The `Link` field should be 'Entire document' and the `Embed` field should be 'Web page.' If everything looks right, then click the `Publish` button. Next, click the `Share` button in the top right corner of the Google Sheets window, select `Get shareable link`, and set the permissions to 'Anyone with the link can view.' The input needed for the `tidytags::read_tags()` function is either the entire URL from the top of the web browser when opened to a TAGS tracker, or a Google Sheet identifier (i.e., the alphanumeric string following "https://docs.google.com/spreadsheets/d/" in the TAGS tracker's URL). Be sure to put quotations marks around the URL or sheet identifier when entering it into `read_tags()` function.

If you're having trouble setting up or publishing the TAGS tracker, see the [Getting started with tidytags](https://bretsw.github.io/tidytags/articles/setup.html) vignette, **Pain Point #1**.


```{r}
tags_url <- "18clYlQeJOc6W5QRuSlJ6_v3snqKJImFhU42bRkM_OX8"
example_df_all <- read_tags(tags_url)
dim(example_df_all)
#> [1] 2564   18
```

**Note that there are alternate ways to access TAGS files.** One way is to simply download a CSV file from Google Sheets. In Google Sheets, navigate to `File -> Download -> Comma-separated values (CSV)` to do so. Be sure to do so from the TAGS Archive page. Once this file is downloaded, you can read it like it like any other CSV using R.

This next code chunk does not run because it is just an example (notice that `eval = FALSE`).


```{r}
example_df_all <- readr::read_csv("my-downloaded-tags-file.csv")
```

## pull_tweet_data()

With a TAGS archive imported into R, {tidytags} allows you to gather quite a bit more information related to the collected tweets with the `pull_tweet_data()` function. This function uses the [{rtweet} package](https://rtweet.info/) (via `rtweet::lookup_statuses()`) to query the Twitter API. Using {rtweet} requires Twitter API keys associated with an approved developer account. Fortunately, the {rtweet} vignette, [Obtaining and using access tokens](https://rtweet.info/articles/auth.html), provides a very thorough guide to obtaining Twitter API keys. For further help getting your own Twitter API keys, see the [Getting started with tidytags](https://bretsw.github.io/tidytags/articles/setup.html) vignette we've written, specifically **Pain Point #2**.

Note that your dataset will often contain fewer rows after running `pull_tweet_data()`. This is because `rtweet::lookup_statuses()` is searching for tweet IDs that are currently available. Any tweets that have been deleted or made "protected" (i.e., private) since TAGS first collected them are dropped from the dataset. Rather than view this as a limitation, we see this as an asset to help ensure our data better reflects the intentions of the accounts whose tweets we have collected (see Fiesler & Proferes, 2018).

Here, we demonstrate two different ways of using `pull_tweet_data()`. The first method is to query the Twitter API with the tweet ID numbers from the `id_str` column returned by {rtweet}. However, a limitation of TAGS is that the numbers in this column are often corrupted because Google Sheets considers them very large numbers (instead of character strings) and rounds them by putting them into exponential form. The results of this first method are stored in the variable `example_after_rtweet_A` below. The second method pulls the tweet ID numbers from the tweet URLs. For example, the tweet with the URL `https://twitter.com/tweet__example/status/1176592704647716864` has a tweet ID of `1176592704647716864`. The results of this second method are stored in the variable `example_after_rtweet_B` below.


```{r}
example_after_rtweet_A <- pull_tweet_data(id_vector = example_df_all$id_str)
example_after_rtweet_B <- pull_tweet_data(url_vector = example_df_all$status_url)
```

The TAGS tracker alone collected 18 variables associated with 2564 tweets. The first method searching with `id_str` collected 90 variables associated with 2215 tweets. Note that this number of rows is at the point at which we collected the data; the number may differ when you carry out this same search. The second method using 'tidytags::get_char_tweet_ids()' collected 90 variables associated with 2215 tweets.

Notice how many more variables are in the dataset after using `pull_tweet_data()`, and how many more tweets are in the dataset when using the second method. Therefore, we strongly recommend the second method, which is why we have included `get_char_tweet_ids()` in the {tidytags} package.

The built-in default of `pull_tweet_data()` is to simply enter the dataframe retrieved from  `read_tags()` and implement method B, retrieving metadata starting with tweet URLs. That is, `pull_tweet_data(read_tags(example_url))`. Take a quick look at the result, viewed with the `glimpse()` function from the {dplyr} package.


```{r}
example_after_rtweet <- pull_tweet_data(read_tags(tags_url))
dplyr::glimpse(example_after_rtweet)
#> Rows: 2,215
#> Columns: 90
#> $ user_id                 <chr> "14215524", "14215524", "14215524", "14215524", "14215524", "14215524",…
#> $ status_id               <chr> "1225122317849657345", "1187960612695019521", "1185978315317764096", "1…
#> $ created_at              <dttm> 2020-02-05 18:21:36, 2019-10-26 05:14:15, 2019-10-20 17:57:19, 2019-10…
#> $ screen_name             <chr> "tadousay", "tadousay", "tadousay", "tadousay", "tadousay", "tadousay",…
#> $ text                    <chr> "Many thanks to @AECTTechTrends for supporting our @gsa_aect with the G…
#> $ source                  <chr> "TweetDeck", "IFTTT", "Twitter for Android", "IFTTT", "TweetDeck", "IFT…
#> $ display_text_width      <dbl> 268, 89, 95, 137, 270, 75, 280, 188, 62, 136, 284, 199, 103, 194, 47, 1…
#> $ reply_to_status_id      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ reply_to_user_id        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ reply_to_screen_name    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ is_quote                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…
#> $ is_retweet              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, FA…
#> $ favorite_count          <int> 8, 3, 0, 3, 14, 10, 12, 7, 2, 0, 1, 15, 32, 12, 7, 0, 0, 0, 9, 0, 0, 0,…
#> $ retweet_count           <int> 3, 0, 0, 0, 7, 0, 0, 2, 0, 1, 0, 2, 4, 3, 0, 1, 1, 2, 1, 5, 3, 4, 7, 7,…
#> $ quote_count             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ reply_count             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ hashtags                <list> [<"uidaho", "UISTEMEdRG", "aect", "aect20", "aect19">, "AECT19", "AECT…
#> $ symbols                 <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
#> $ urls_url                <list> ["doi.org/10.1007/s11528…", "bit.ly/2ofqpjs", NA, "bit.ly/2W3PRoC", NA…
#> $ urls_t.co               <list> ["https://t.co/8MuP9Mza8f", "https://t.co/OlWIR3JcZc", NA, "https://t.…
#> $ urls_expanded_url       <list> ["https://doi.org/10.1007/s11528-020-00477-5", "http://bit.ly/2ofqpjs"…
#> $ media_url               <list> [NA, "http://pbs.twimg.com/media/EHx74b1W4AY11Kb.jpg", "http://pbs.twi…
#> $ media_t.co              <list> [NA, "https://t.co/79CGsiSCHD", "https://t.co/aJiDeNQoUp", "https://t.…
#> $ media_expanded_url      <list> [NA, "https://twitter.com/tadousay/status/1187960612695019521/photo/1"…
#> $ media_type              <list> [NA, "photo", "photo", "photo", "photo", "photo", NA, "photo", "photo"…
#> $ ext_media_url           <list> [NA, "http://pbs.twimg.com/media/EHx74b1W4AY11Kb.jpg", "http://pbs.twi…
#> $ ext_media_t.co          <list> [NA, "https://t.co/79CGsiSCHD", "https://t.co/aJiDeNQoUp", "https://t.…
#> $ ext_media_expanded_url  <list> [NA, "https://twitter.com/tadousay/status/1187960612695019521/photo/1"…
#> $ ext_media_type          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ mentions_user_id        <list> [<"804807943", "922536306437181440">, NA, NA, NA, "12030342", NA, NA, …
#> $ mentions_screen_name    <list> [<"AECTTechTrends", "gsa_aect">, NA, NA, NA, "AECT", NA, NA, NA, NA, <…
#> $ lang                    <chr> "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "en",…
#> $ quoted_status_id        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_text             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_created_at       <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_source           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_favorite_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_retweet_count    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_user_id          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_screen_name      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_name             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_followers_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_friends_count    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_statuses_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_location         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_description      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ quoted_verified         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ retweet_status_id       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "1187778827180752896", NA, NA, NA, …
#> $ retweet_text            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "#AECT19 #aect19inspired Here are t…
#> $ retweet_created_at      <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, 2019-10-25 17:11:54, NA, NA, NA, N…
#> $ retweet_source          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "TweetDeck", NA, NA, NA, NA, NA, "T…
#> $ retweet_favorite_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, NA, NA, NA, 6, 5, 5, NA,…
#> $ retweet_retweet_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA, NA, NA, NA, 1, 1, 2, NA,…
#> $ retweet_user_id         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "11092692", NA, NA, NA, NA, NA, "41…
#> $ retweet_screen_name     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "gravesle", NA, NA, NA, NA, NA, "Fa…
#> $ retweet_name            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "Dr. Leigh Graves Wolf", NA, NA, NA…
#> $ retweet_followers_count <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, 5850, NA, NA, NA, NA, NA, 98, 419, …
#> $ retweet_friends_count   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, 6431, NA, NA, NA, NA, NA, 117, 624,…
#> $ retweet_statuses_count  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, 45252, NA, NA, NA, NA, NA, 251, 141…
#> $ retweet_location        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "Michigan/Galway/Arizona/Online", N…
#> $ retweet_description     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "I like to share and listen. Clinic…
#> $ retweet_verified        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, FALSE, NA, NA, NA, NA, NA, FALSE, F…
#> $ place_url               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ place_name              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ place_full_name         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ place_type              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ country                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ country_code            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ geo_coords              <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>,…
#> $ coords_coords           <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>,…
#> $ bbox_coords             <list> [<NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA, NA, NA, NA, NA>, <…
#> $ status_url              <chr> "https://twitter.com/tadousay/status/1225122317849657345", "https://twi…
#> $ name                    <chr> "Tonia A. Dousay", "Tonia A. Dousay", "Tonia A. Dousay", "Tonia A. Dous…
#> $ location                <chr> "Moscow, ID", "Moscow, ID", "Moscow, ID", "Moscow, ID", "Moscow, ID", "…
#> $ description             <chr> "❖ @UIdaho Assoc Prof of #LearningSci ⋄ Assoc Dean of #Accreditation ⋄ …
#> $ url                     <chr> "https://t.co/mqTPJf37uj", "https://t.co/mqTPJf37uj", "https://t.co/mqT…
#> $ protected               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…
#> $ followers_count         <int> 2073, 2073, 2073, 2073, 2073, 2073, 2073, 2073, 2073, 2073, 2073, 2073,…
#> $ friends_count           <int> 1261, 1261, 1261, 1261, 1261, 1261, 1261, 1261, 1261, 1261, 1261, 1261,…
#> $ listed_count            <int> 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 183, 1…
#> $ statuses_count          <int> 11623, 11623, 11623, 11623, 11623, 11623, 11623, 11623, 11623, 11623, 1…
#> $ favourites_count        <int> 4169, 4169, 4169, 4169, 4169, 4169, 4169, 4169, 4169, 4169, 4169, 4169,…
#> $ account_created_at      <dttm> 2008-03-25 13:56:07, 2008-03-25 13:56:07, 2008-03-25 13:56:07, 2008-03…
#> $ verified                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F…
#> $ profile_url             <chr> "https://t.co/mqTPJf37uj", "https://t.co/mqTPJf37uj", "https://t.co/mqT…
#> $ profile_expanded_url    <chr> "http://about.me/tadousay", "http://about.me/tadousay", "http://about.m…
#> $ account_lang            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ profile_banner_url      <chr> "https://pbs.twimg.com/profile_banners/14215524/1550516097", "https://p…
#> $ profile_background_url  <chr> "http://abs.twimg.com/images/themes/theme9/bg.gif", "http://abs.twimg.c…
#> $ profile_image_url       <chr> "http://pbs.twimg.com/profile_images/1214316658635886593/SrpJRUZj_norma…
```

At this point, the purpose of {tidytags} should be restated. TAGS tweet trackers are easily set up and maintained, and does an excellent job passively collecting tweets over time. For instance, the example TAGS tracker we demo here has collected thousands of tweets related to the AECT 2019 annual convention since September 30, 2019. In contrast, running this query now using `rtweet::search_tweets()` is limited by Twitter's API, meaning that an {rtweet} search can only go back in time 6-9 days, and is limited to returning at most 18,000 tweets per query. So, if you are interested in tweets about AECT 2019, today you could get almost no meaningful data using {rtweet} alone.


```{r}
rtweet_today <-
  rtweet::search_tweets("#aect19 OR #aect2019 OR #aect19inspired")
```

You can see that an {rtweet} search for #AECT19 tweets run today returns 0tweets.

In sum, although a TAGS tracker is great for easily collecting tweets over time (breadth), it lacks depth in terms of metadata is returned related to the gathered tweets. Specifically, TAGS returns information on at most 18 variables; in contrast, {rtweet} returns information on up to 90 variables. Thus, our package {tidytags} brings together the breadth of TAGS with the depth of {rtweet}.

## lookup_many_tweets()

The Twitter API only allows the looking up of 90,000 tweet IDs at a time, a rate limit which resets after 15 minutes. Hence `rtweet::lookup_statuses()` will only return results for the first 90,000 tweet IDs in your dataset. The function `tidytags::lookup_many_tweets()` will automatically break your dataset into batches of 90,000 tweets, looking up one batch per 15 minutes until finished. Note that `lookup_many_tweets()` also works for datasets with fewer than 90,000 tweets as well.

Because our AECT 2019 examples includes fewer than 90,000 tweets (and because `lookup_many_tweets()` involves waiting for 15 minutes between batches), we do not include an example here. However, this function can be used in the same way as `pull_tweet_data()`.

## process_tweets()

After `pull_tweet_data()` is used to collect additional information from TAGS tweet IDs (in this case, the `example_after_rtweet` dataframe), the {tidytags} function `process_tweets()` can be used to calculate additional attributes and add these to the dataframe as new columns. Specifically, 10 new variables are added: word_count, character_count, mentions_count, hashtags_count_api, hashtags_count_regex, has_hashtags, urls_count_api, urls_count_regex, is_reply, and is_self_reply. This results in 100 variables associated with the collected tweets.


```{r}
example_processed <- process_tweets(example_after_rtweet)
```

Notice that you now have 100 variables associated 2215 tweets.

At this point, depending on your research questions, you may wish to calculate some descriptive statistics associated with this tweet data. For instance the mean number of characters per tweet:


```{r}
mean_char <- round(mean(example_processed$character_count), 2)
sd_char <- round(sd(example_processed$character_count), 2)
```

This shows that the mean number of characters per tweet is 182.81 (SD = 75.69).

Or, perhaps, the mean, median, and max number of *hashtags per tweet* would be useful to know:


```{r}
mean_hash <- round(mean(example_processed$hashtags_count_regex), 2)
sd_hash <- round(sd(example_processed$hashtags_count_regex), 2)
median_hash <- median(example_processed$hashtags_count_regex)
max_hash <- max(example_processed$hashtags_count_regex)
```

The mean number of hashtags per tweet is 2.19 (SD = 1.49). The median is 2, and the maximum number of hashtags in a tweet is 12.

## get_url_domain()

The {tidytags} function `get_url_domain()` combines the `expand_urls()` function from the {longurl} package and the `domain()` function from the {urltools} package to easily return the domain names of any hyperlinks including in tweets. Please note that these two packages are required to use this function (but they are not installed automatically when {tidytags} is installed. Note that using `longurl::expand_urls()` is a necessary step because Twitter automatically shortens any hyperlinks included in tweets.

As an example, `get_url_domain()` finds that the domain in the shortened URL "http://bit.ly/2SfWO3K" is "aect.org":


```{r}
short_url <- "http://bit.ly/2SfWO3K"
get_url_domain(short_url)
#> [1] "aect.org"
```

It may also be of interest to examine which websites get linked to most often in your dataset. `get_url_domain()` can be combined with a function from base R like `table()` to calculate frequency counts for domains present in the dataset. This process is useful to get a picture of to where else on the Internet tweeters are directing their readers' attention.

Keep in mind, however, that this process is a bit slow.

```{r}
example_urls <- purrr::flatten_chr(example_processed$urls_url)
example_urls <- example_urls[!is.na(example_urls)] # Remove NA values
example_domains <- get_url_domain(example_urls)
domain_table <- tibble::as_tibble(table(example_domains))
domain_table_sorted <- dplyr::arrange(domain_table, desc(n))
head(domain_table_sorted, 20)
#> # A tibble: 20 x 2
#>    example_domains                 n
#>    <chr>                       <int>
#>  1 twitter.com                   134
#>  2 convention2.allacademic.com    23
#>  3 bit.ly                         15
#>  4 instagram.com                  13
#>  5 youtube.com                    10
#>  6 docs.google.com                 8
#>  7 drive.google.com                7
#>  8 accounts.google.com             6
#>  9 bretsw.github.io                6
#> 10 nodexlgraphgallery.org          6
#> 11 caranorth.com                   5
#> 12 flipsnack.com                   5
#> 13 litnet.co.za                    5
#> 14 shor.by                         5
#> 15 app.core-apps.com               4
#> 16 apps.apple.com                  4
#> 17 isfsu.blogspot.com              4
#> 18 linkedin.com                    4
#> 19 play.google.com                 4
#> 20 springer.com                    4
```

Unsurprisingly, in this dataset, by far the most common domain (as of September 30, 2020) was "twitter.com", meaning that AECT 2019 tweeters were linking most often to other Twitter content. Other common domains included "convention2.allacademic.com" (i.e., the host of the conference website, including the schedule and session information) as well as "instagram.com" and "youtube.com", where tweeters likely shared conference-related content.

## geocode_tags()

Another area to explore is where tweeters in the dataset are from (or, at least, the location they self-identify in their Twitter profiles). {tidytags} makes this straightforward with the `geocode_tags()` function. Note that `geocode_tags()` should be used after additional metadata have been retrieved with `tidytags::pull_tweet_data()`.

`geocode_tags()` pulls from the OpenCage Geocoding API, which requires a OpenCage Geocoding API Key. You can easily secure a key through OpenCage directly; their Quick Start guide offers helpful guidance ([read more here](https://docs.ropensci.org/opencage/#quickstart)). Once you have the key, the [OpenCage Geocoding API Documentation](https://opencagedata.com/api) offers many more additional helps.

If you're having trouble setting up the Google Geocoding API Key, see the [Getting started with tidytags](https://bretsw.github.io/tidytags/articles/setup.html) vignette we've written, specifically **Pain Point #3**.

You can pair `geocode_tags()` with the {mapview} package to allow for quick, interactive viewing of the geocoded data; read more about mapview [here](https://r-spatial.github.io/mapview/). There are many additional R packages that can plot coordinates on a map; which you choose is largely a matter of personal preference.

First, we identify the unique individuals in the dataset:

```{r}
example_unique_places <-
  dplyr::distinct(example_processed, location, .keep_all = TRUE)
```

Then, we geocode the a random sample of 10% of locations with the `geocode_tags()` function, which takes a tibble and outputs a vector of geo-coordinates.

```{r}
sample_unique_places <- dplyr::sample_n(example_unique_places, 10)
example_geo_coords <- geocode_tags(sample_unique_places)
example_geo_coords
#> # A tibble: 10 x 3
#>    location            latitude longitude
#>    <chr>                  <dbl>     <dbl>
#>  1 Emporia, KS            38.4     -96.2 
#>  2 Neverland              36.5    -122.  
#>  3 Kenya                   1.44     38.4 
#>  4 Norman, Oklahoma       35.2     -97.4 
#>  5 Pensacola, Florida     30.4     -87.2 
#>  6 Iowa                   41.9     -93.3 
#>  7 Tallahassee            30.4     -84.3 
#>  8 Geneva, Switzerland    46.2       6.15
#>  9 Ocala, FL              29.2     -82.1 
#> 10 Oklahoma City, OK      35.5     -97.5
```

Finally, it's easy to visualize the data, with a number of packages supporting the visualization of geo-coordinates. For instance, you can use the `mapview()` function from the {mapview} package:


```{r}
locations <-
  sf::st_as_sf(
    example_geo_coords,
    coords = c(x = "longitude", y = "latitude"),
    crs = 4326)

example_map <- mapview::mapview(locations)
```

At this point, you can view an interactive map in your R environment simply by calling `example_map`.

## get_replies(), get_retweets(), get_quotes(), get_mentions()

These functions quickly subset the data, returning just the tweets of the type indicated by the function name (e.g., `get_replies()` returns only reply tweets). The `get_` family of {tidytags} functions can be used to look at home many tweets of each type are present in the dataset.

In the dataset of 2215 tweets, there are 76 replies, 1191 retweets, 106 quote tweets, and 3204.

## get_upstream_replies()

If your research questions conceptualize your tweet dataset as a conversation or affinity space, it may be useful to retrieve and add additional tweets. Specifically, TAGS collects tweets that contain one or more keywords or text strings. For example, the TAGS tracker we have been working with in this vignette collected tweets containing the keywords: `#aect19` OR `#aect2019` OR `#aect19inspired`. This is a reasonable approach, from a researchers' point of view. However, participants who have been following or contributing to these hashtags would also see additional tweets in these "conversations" because Twitter connects together tweets that reply to other tweets into potentially lengthy *reply threads*. Tweets in a reply thread are all displayed to a user viewing tweets on Twitter's platform, but because some tweets in a thread may not contain the hashtag of interest, not all tweets in a user's experience of a conversation would be collected by TAGS. Additionally, tweets contained in a reply thread but composed before the TAGS tracker was initiated would also be left out of the dataset.

There is a solution to this problem. Because the Twitter API offers a `reply_to_status_id` column, it is possible to iteratively reconstruct reply threads in an *upstream* direction, that is, retrieving tweets composed earlier than replies in the dataset. We include the `get_upstream_replies` in {tidytags} to streamline this process. We also print output at each iteration to demonstrate how the process is progressing.


```{r}
example_with_upstream <- get_upstream_replies(example_processed)
```

The dataset contained 2215 tweets at the start. Running `get_upstream_replies()` added 36 new tweets.

Unfortunately, due to limitations in what information is given by the Twitter API, it is not practical to retrieve *downstream* replies, or those tweets in a reply thread that follow a tweet in the dataset but neglect to include the hashtag or keyword.

## create_edgelist()

Another useful approach to social media research is *social network analysis*. Getting started with social network analysis is as simple as producing an *edgelist*, a two-column dataframe listing *senders* and *receivers*. An edgelist gives a complete accounting of whom is interacting with whom. In Twitter, this is complicated somewhat by the number of ways a user is able to interact with someone else, namely, through replying, retweeting, quote tweeting, mentioning, and liking tweets. The {tidytags} function `create_edgelist()` uses `get_replies()`, `get_retweets()`, `get_quotes()`, and `get_mentions()` to create an edgelist that takes into account these four different types of interaction. `create_edgelist()` returns a dataframe with three columns: two for the sender and receiver Twitter handles, and a third column listing the edge type (i.e., the form of interaction).

Run `create_edgelist()` after completing `get_upstream_replies()` for a complete picture of the interactions.


```{r}
example_edgelist <- create_edgelist(example_with_upstream)
head(example_edgelist, 20)
#> # A tibble: 20 x 3
#>    sender         receiver        edge_type
#>    <chr>          <chr>           <chr>    
#>  1 lbukunAA       lbukunAA        reply    
#>  2 bretsw         bretsw          reply    
#>  3 bretsw         bretsw          reply    
#>  4 bretsw         FakeBobGagne    reply    
#>  5 bretsw         eromerohall     reply    
#>  6 bretsw         bretsw          reply    
#>  7 AECT           jmenglund03     reply    
#>  8 correia65      AnnaRoseLeach   reply    
#>  9 caranorth11    FredWBaker      reply    
#> 10 PaulineMuljana robmoore3       reply    
#> 11 PaulineMuljana WEHSLibrary     reply    
#> 12 PaulineMuljana soniastic       reply    
#> 13 PaulineMuljana AmyLomellini_ID reply    
#> 14 PaulineMuljana tintinluo       reply    
#> 15 nicolapallitt  eromerohall     reply    
#> 16 nicolapallitt  aectclt         reply    
#> 17 michaelmgrant  EdTech_UofSC    reply    
#> 18 michaelmgrant  gsa_aect        reply    
#> 19 michaelmgrant  nicolapallitt   reply    
#> 20 michaelmgrant  robmoore3       reply
```

We can then easily visualize the edgelist as a sociogram using the {tidygraph} and {ggraph} packages.

First, create graph object using {tidygraph}:


```{r}
example_graph <-
  tidygraph::as_tbl_graph(example_edgelist)
example_graph <-
  dplyr::mutate(example_graph,
                popularity = tidygraph::centrality_degree(mode = 'in'))
```

Then plot using {ggraph}:


```{r}
ggraph::ggraph(example_graph, layout = 'kk') +
  ggraph::geom_edge_arc(alpha = .2, width = .5, strength = .5, edge_colour = 'steelblue') +
  ggraph::geom_node_point(alpha = .4, ggplot2::aes(size = popularity)) +
  ggplot2::scale_size(range = c(1,10))
```

<img src="vignette-network-visualization-1.png" title="plot of chunk network-visualization" alt="plot of chunk network-visualization" width="100%" />

Running `create_edgelist()` also provides a simple way to re-look at how many tweets of each type are present in the dataset, using the `count()` function from {dplyr}.


```{r}
dplyr::count(example_edgelist, edge_type, sort = TRUE)
#> # A tibble: 4 x 2
#>   edge_type       n
#>   <chr>       <int>
#> 1 mention      3261
#> 2 retweet      1191
#> 3 quote-tweet   113
#> 4 reply          91
```

Note that {tidytags} does not yet have a function `get_likes()` because this process is much more difficult given the information provided by the Twitter API.

## add_users_data()

Finally, {tidytags} also has functionality to add user-level data to an edgelist through the function `tidytags::add_users_data()`. These additional features are very useful when taking an inferential approach to social network analysis, such as building *influence* or *selection* models.


```{r}
example_senders_receivers_data <- add_users_data(example_edgelist)
dplyr::glimpse(example_senders_receivers_data)
#> Rows: 4,656
#> Columns: 181
#> $ sender                           <chr> "lbukunAA", "bretsw", "bretsw", "bretsw", "bretsw", "bretsw", …
#> $ receiver                         <chr> "lbukunAA", "bretsw", "bretsw", "FakeBobGagne", "eromerohall",…
#> $ edge_type                        <chr> "reply", "reply", "reply", "reply", "reply", "reply", "reply",…
#> $ user_id_sender                   <chr> "2950104673", "53167706", "53167706", "53167706", "53167706", …
#> $ status_id_sender                 <chr> "1310962681407565824", "1329781079939670019", "132978107993967…
#> $ created_at_sender                <dttm> 2020-09-29 15:20:34, 2020-11-20 13:38:10, 2020-11-20 13:38:10…
#> $ text_sender                      <chr> "Join Us For a Conversation on \"The Future of Education\nEduc…
#> $ source_sender                    <chr> "Twitter for Android", "Twitter Web App", "Twitter Web App", "…
#> $ display_text_width_sender        <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ reply_to_status_id_sender        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ reply_to_user_id_sender          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ reply_to_screen_name_sender      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ is_quote_sender                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
#> $ is_retweet_sender                <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, …
#> $ favorite_count_sender            <int> 0, 0, 0, 0, 0, 0, 0, 25, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1…
#> $ retweet_count_sender             <int> 2, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 7, 7, 0, 0, 0, 0, 0,…
#> $ quote_count_sender               <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ reply_count_sender               <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ hashtags_sender                  <list> [NA, "aectRTD", "aectRTD", "aectRTD", "aectRTD", "aectRTD", N…
#> $ symbols_sender                   <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ urls_url_sender                  <list> [NA, NA, NA, NA, NA, NA, NA, "twitter.com/i/web/status/1…", N…
#> $ urls_t.co_sender                 <list> [NA, NA, NA, NA, NA, NA, NA, "https://t.co/2FNDAipTnV", NA, "…
#> $ urls_expanded_url_sender         <list> [NA, NA, NA, NA, NA, NA, NA, "https://twitter.com/i/web/statu…
#> $ media_url_sender                 <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ media_t.co_sender                <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ media_expanded_url_sender        <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ media_type_sender                <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ ext_media_url_sender             <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ ext_media_t.co_sender            <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ ext_media_expanded_url_sender    <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ ext_media_type_sender            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ mentions_user_id_sender          <list> ["840655475444183047", <"1197270185960361984", "12030342">, <…
#> $ mentions_screen_name_sender      <list> ["OkStateEMTSA", <"aectrtd", "AECT">, <"aectrtd", "AECT">, <"…
#> $ lang_sender                      <chr> "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "e…
#> $ quoted_status_id_sender          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_text_sender               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_created_at_sender         <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
#> $ quoted_source_sender             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_favorite_count_sender     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_retweet_count_sender      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_user_id_sender            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_screen_name_sender        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_name_sender               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_followers_count_sender    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_friends_count_sender      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_statuses_count_sender     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_location_sender           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_description_sender        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_verified_sender           <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_status_id_sender         <chr> "1310961988206497794", "1329780970636124164", "132978097063612…
#> $ retweet_text_sender              <chr> "Join Us For a Conversation on \"The Future of Education\nEduc…
#> $ retweet_created_at_sender        <dttm> 2020-09-29 15:17:49, 2020-11-20 13:37:44, 2020-11-20 13:37:44…
#> $ retweet_source_sender            <chr> "Twitter Web App", "Twitter Web App", "Twitter Web App", "Twit…
#> $ retweet_favorite_count_sender    <int> 3, 0, 0, 0, 0, 0, 14, NA, 1, NA, NA, NA, NA, NA, 21, 21, NA, N…
#> $ retweet_retweet_count_sender     <int> 2, 1, 1, 1, 1, 1, 1, NA, 1, NA, NA, NA, NA, NA, 7, 7, NA, NA, …
#> $ retweet_user_id_sender           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_screen_name_sender       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_name_sender              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_followers_count_sender   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_friends_count_sender     <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_statuses_count_sender    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_location_sender          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_description_sender       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_verified_sender          <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_url_sender                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_name_sender                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_full_name_sender           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_type_sender                <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ country_sender                   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ country_code_sender              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ geo_coords_sender                <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, …
#> $ coords_coords_sender             <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, …
#> $ bbox_coords_sender               <list> [<NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA, NA, NA, N…
#> $ status_url_sender                <chr> "https://twitter.com/NA/status/1310962681407565824", "https://…
#> $ name_sender                      <chr> "Ayodeji Ibukun", "Bret Staudt Willet", "Bret Staudt Willet", …
#> $ location_sender                  <chr> "Oklahoma, USA", "Pennsylvania, USA", "Pennsylvania, USA", "Pe…
#> $ description_sender               <chr> "B.Engrg MS MNSE", "PhD candidate #MSUepet | Studying networke…
#> $ url_sender                       <chr> "https://t.co/kVfuPQQfYs", "https://t.co/9lV9hWdb9F", "https:/…
#> $ protected_sender                 <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
#> $ followers_count_sender           <int> 40, 1932, 1932, 1932, 1932, 1932, 3849, 2060, 7431, 419, 419, …
#> $ friends_count_sender             <int> 449, 3496, 3496, 3496, 3496, 3496, 533, 1655, 3785, 624, 624, …
#> $ listed_count_sender              <int> 0, 52, 52, 52, 52, 52, 122, 23, 189, 2, 2, 2, 2, 2, 129, 129, …
#> $ statuses_count_sender            <int> 103, 6744, 6744, 6744, 6744, 6744, 2600, 515, 18937, 1414, 141…
#> $ favourites_count_sender          <int> 489, 9194, 9194, 9194, 9194, 9194, 2906, 5696, 32438, 6057, 60…
#> $ account_created_at_sender        <dttm> 2014-12-29 12:06:33, 2009-07-02 19:51:43, 2009-07-02 19:51:43…
#> $ verified_sender                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
#> $ profile_url_sender               <chr> "https://t.co/kVfuPQQfYs", "https://t.co/9lV9hWdb9F", "https:/…
#> $ profile_expanded_url_sender      <chr> "http://www.ayoibukun.com", "http://bretsw.com", "http://brets…
#> $ account_lang_sender              <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ profile_banner_url_sender        <chr> "https://pbs.twimg.com/profile_banners/2950104673/1574622610",…
#> $ profile_background_url_sender    <chr> "http://abs.twimg.com/images/themes/theme1/bg.png", "http://ab…
#> $ profile_image_url_sender         <chr> "http://pbs.twimg.com/profile_images/1086275206274895874/ABYBQ…
#> $ user_id_receiver                 <chr> "2950104673", "53167706", "53167706", "4130346912", "918747876…
#> $ status_id_receiver               <chr> "1310962681407565824", "1329781079939670019", "132978107993967…
#> $ created_at_receiver              <dttm> 2020-09-29 15:20:34, 2020-11-20 13:38:10, 2020-11-20 13:38:10…
#> $ text_receiver                    <chr> "Join Us For a Conversation on \"The Future of Education\nEduc…
#> $ source_receiver                  <chr> "Twitter for Android", "Twitter Web App", "Twitter Web App", "…
#> $ display_text_width_receiver      <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ reply_to_status_id_receiver      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, "1331295214137470990", NA,…
#> $ reply_to_user_id_receiver        <chr> NA, NA, NA, NA, NA, NA, "54756731", NA, NA, "12363792", NA, NA…
#> $ reply_to_screen_name_receiver    <chr> NA, NA, NA, NA, NA, NA, "ireneamelia1", NA, NA, "jonbecker", N…
#> $ is_quote_receiver                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
#> $ is_retweet_receiver              <lgl> TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, FAL…
#> $ favorite_count_receiver          <int> 0, 0, 0, 3, 7, 0, 0, 0, 0, 0, 3, 1, 0, 2, 7, 0, 0, 1, 0, 0, 3,…
#> $ retweet_count_receiver           <int> 2, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 9, 0, 7, 0, 1,…
#> $ quote_count_receiver             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ reply_count_receiver             <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ hashtags_receiver                <list> [NA, "aectRTD", "aectRTD", "aect19", NA, "aectRTD", NA, <"adu…
#> $ symbols_receiver                 <list> [NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
#> $ urls_url_receiver                <list> [NA, NA, NA, NA, "enildaromero.com/2020/11/22/we-…", NA, "twi…
#> $ urls_t.co_receiver               <list> [NA, NA, NA, NA, "https://t.co/VUin8FgkSm", NA, "https://t.co…
#> $ urls_expanded_url_receiver       <list> [NA, NA, NA, NA, "http://enildaromero.com/2020/11/22/we-shoul…
#> $ media_url_receiver               <list> [NA, NA, NA, "http://pbs.twimg.com/tweet_video_thumb/EHvxWe7X…
#> $ media_t.co_receiver              <list> [NA, NA, NA, "https://t.co/oOFVcSXkQB", NA, NA, NA, NA, NA, N…
#> $ media_expanded_url_receiver      <list> [NA, NA, NA, "https://twitter.com/FakeBobGagne/status/1187808…
#> $ media_type_receiver              <list> [NA, NA, NA, "photo", NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…
#> $ ext_media_url_receiver           <list> [NA, NA, NA, "http://pbs.twimg.com/tweet_video_thumb/EHvxWe7X…
#> $ ext_media_t.co_receiver          <list> [NA, NA, NA, "https://t.co/oOFVcSXkQB", NA, NA, NA, NA, NA, N…
#> $ ext_media_expanded_url_receiver  <list> [NA, NA, NA, "https://twitter.com/FakeBobGagne/status/1187808…
#> $ ext_media_type_receiver          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ mentions_user_id_receiver        <list> ["840655475444183047", <"1197270185960361984", "12030342">, <…
#> $ mentions_screen_name_receiver    <list> ["OkStateEMTSA", <"aectrtd", "AECT">, <"aectrtd", "AECT">, NA…
#> $ lang_receiver                    <chr> "en", "en", "en", "en", "en", "en", "en", "en", "en", "en", "e…
#> $ quoted_status_id_receiver        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_text_receiver             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_created_at_receiver       <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
#> $ quoted_source_receiver           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_favorite_count_receiver   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_retweet_count_receiver    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_user_id_receiver          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_screen_name_receiver      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_name_receiver             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_followers_count_receiver  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_friends_count_receiver    <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_statuses_count_receiver   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_location_receiver         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_description_receiver      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ quoted_verified_receiver         <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_status_id_receiver       <chr> "1310961988206497794", "1329780970636124164", "132978097063612…
#> $ retweet_text_receiver            <chr> "Join Us For a Conversation on \"The Future of Education\nEduc…
#> $ retweet_created_at_receiver      <dttm> 2020-09-29 15:17:49, 2020-11-20 13:37:44, 2020-11-20 13:37:44…
#> $ retweet_source_receiver          <chr> "Twitter Web App", "Twitter Web App", "Twitter Web App", NA, N…
#> $ retweet_favorite_count_receiver  <int> 3, 0, 0, NA, NA, 0, NA, NA, NA, NA, NA, NA, 18, NA, NA, NA, 28…
#> $ retweet_retweet_count_receiver   <int> 2, 1, 1, NA, NA, 1, NA, NA, NA, NA, NA, NA, 7, NA, NA, NA, 9, …
#> $ retweet_user_id_receiver         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_screen_name_receiver     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_name_receiver            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_followers_count_receiver <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_friends_count_receiver   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_statuses_count_receiver  <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_location_receiver        <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_description_receiver     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ retweet_verified_receiver        <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_url_receiver               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_name_receiver              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_full_name_receiver         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ place_type_receiver              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ country_receiver                 <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ country_code_receiver            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ geo_coords_receiver              <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, …
#> $ coords_coords_receiver           <list> [<NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, <NA, NA>, …
#> $ bbox_coords_receiver             <list> [<NA, NA, NA, NA, NA, NA, NA, NA>, <NA, NA, NA, NA, NA, NA, N…
#> $ status_url_receiver              <chr> "https://twitter.com/NA/status/1310962681407565824", "https://…
#> $ name_receiver                    <chr> "Ayodeji Ibukun", "Bret Staudt Willet", "Bret Staudt Willet", …
#> $ location_receiver                <chr> "Oklahoma, USA", "Pennsylvania, USA", "Pennsylvania, USA", "",…
#> $ description_receiver             <chr> "B.Engrg MS MNSE", "PhD candidate #MSUepet | Studying networke…
#> $ url_receiver                     <chr> "https://t.co/kVfuPQQfYs", "https://t.co/9lV9hWdb9F", "https:/…
#> $ protected_receiver               <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
#> $ followers_count_receiver         <int> 40, 1932, 1932, 98, 1337, 1932, 658, 547, 1124, 1231, 855, 151…
#> $ friends_count_receiver           <int> 449, 3496, 3496, 117, 1213, 3496, 608, 532, 1285, 706, 422, 24…
#> $ listed_count_receiver            <int> 0, 52, 52, 3, 90, 52, 77, 11, 102, 52, 18, 0, 6, 9, 90, 5, 16,…
#> $ statuses_count_receiver          <int> 103, 6744, 6744, 251, 9195, 6744, 2878, 2403, 16406, 13629, 41…
#> $ favourites_count_receiver        <int> 489, 9194, 9194, 137, 8594, 9194, 1995, 1783, 16573, 522, 2202…
#> $ account_created_at_receiver      <dttm> 2014-12-29 12:06:33, 2009-07-02 19:51:43, 2009-07-02 19:51:43…
#> $ verified_receiver                <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE,…
#> $ profile_url_receiver             <chr> "https://t.co/kVfuPQQfYs", "https://t.co/9lV9hWdb9F", "https:/…
#> $ profile_expanded_url_receiver    <chr> "http://www.ayoibukun.com", "http://bretsw.com", "http://brets…
#> $ account_lang_receiver            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
#> $ profile_banner_url_receiver      <chr> "https://pbs.twimg.com/profile_banners/2950104673/1574622610",…
#> $ profile_background_url_receiver  <chr> "http://abs.twimg.com/images/themes/theme1/bg.png", "http://ab…
#> $ profile_image_url_receiver       <chr> "http://pbs.twimg.com/profile_images/1086275206274895874/ABYBQ…
```

We note that although use of Google Sheets is unidirectional (We use TAGS to access data and process the data in R but do not plan for users of the package to update the TAGS sheet with the processed data), you could push data to the TAGS sheet (using the [{googlesheets4}](https://github.com/tidyverse/googlesheets4) package) or store the processed data as a CSV (see `write_csv()`), among other options.

## Getting help

{tidytags} is still a work in progress, so we fully expect that there are still some bugs to work out and functions to document better. If you find an issue, have a question, or think of something that you really wish {tidytags} would do for you, don't hesitate to [email Bret](mailto:bret@bretsw.com) or reach out on Twitter: [\@bretsw](https://twitter.com/bretsw) and [\@jrosenberg6432](https://twitter.com/jrosenberg6432).

You can also [submit an issue on Github](https://github.com/bretsw/tidytags/issues/).

You may also wish too try some general troubleshooting strategies:

- Try to find out what the specific problem is
  -  Identify what is *not* causing the problem
- "Unplug and plug it back in" - restart R, close and reopen R
- Reach out to others! Sharing what is causing an issue can often help to clarify the problem.
  - RStudio Community - https://community.rstudio.com/ (highly recommended!)
  - Twitter hashtag: #rstats
- General strategies on learning more: https://datascienceineducation.com/c17.html

